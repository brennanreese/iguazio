{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register a Model with Iguazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-03-29 10:23:22,760 [info] loaded project default from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\"default\", \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a model trained from anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/brennan/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 350kB/s]\n",
      "Downloading: 100%|██████████| 420M/420M [00:49<00:00, 8.93MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/brennan/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.2kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 1.97MB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 3.89MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0724,  0.1518, -0.1076,  ..., -0.3008,  0.1606,  0.4223],\n",
      "         [ 0.1667, -0.2562, -0.0170,  ...,  0.1399,  0.6332, -0.0106],\n",
      "         [-0.2398, -0.5034,  0.7445,  ..., -0.5338,  0.1721,  0.4689],\n",
      "         ...,\n",
      "         [ 0.1391, -0.2378,  0.3950,  ..., -0.1814, -0.2512,  0.3334],\n",
      "         [-0.1951, -0.1774, -0.4429,  ...,  0.7163, -0.1154, -0.3983],\n",
      "         [ 0.8002,  0.0795, -0.2366,  ...,  0.2992, -0.7405, -0.2355]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8777, -0.3466, -0.7859,  0.7636,  0.3192, -0.0406,  0.8808,  0.3264,\n",
      "         -0.6340, -1.0000, -0.3372,  0.7651,  0.9787,  0.6349,  0.9301, -0.6971,\n",
      "         -0.1388, -0.6554,  0.3605, -0.5844,  0.7168,  0.9999,  0.1679,  0.3189,\n",
      "          0.5397,  0.9556, -0.7769,  0.9285,  0.9424,  0.6922, -0.7314,  0.2183,\n",
      "         -0.9820, -0.2805, -0.8716, -0.9896,  0.3713, -0.7212,  0.0130,  0.0349,\n",
      "         -0.8949,  0.2738,  0.9999,  0.0101,  0.2831, -0.3270, -1.0000,  0.2574,\n",
      "         -0.8385,  0.7437,  0.6762,  0.4606,  0.1859,  0.5370,  0.4520,  0.0083,\n",
      "         -0.0953,  0.0864, -0.2178, -0.5224, -0.6079,  0.3247, -0.7957, -0.8733,\n",
      "          0.7342,  0.6144, -0.1899, -0.3692, -0.0340, -0.0295,  0.8527,  0.2935,\n",
      "         -0.0815, -0.8645,  0.4616,  0.2433, -0.6444,  1.0000, -0.4868, -0.9622,\n",
      "          0.6861,  0.6583,  0.6026, -0.1201,  0.5905, -1.0000,  0.3676, -0.0947,\n",
      "         -0.9857,  0.2678,  0.4697, -0.2136,  0.4728,  0.6358, -0.5858, -0.5075,\n",
      "         -0.2408, -0.6989, -0.3751, -0.2285,  0.1460, -0.3199, -0.2373, -0.4399,\n",
      "          0.3565, -0.4643, -0.3309,  0.5686,  0.0289,  0.7175,  0.3797, -0.3978,\n",
      "          0.4588, -0.9511,  0.6984, -0.3399, -0.9840, -0.6459, -0.9858,  0.6344,\n",
      "         -0.2784, -0.2379,  0.9410, -0.1459,  0.3988, -0.1058, -0.6132, -1.0000,\n",
      "         -0.6208, -0.5531, -0.1686, -0.3675, -0.9615, -0.9386,  0.5650,  0.9459,\n",
      "          0.2192,  0.9997, -0.3732,  0.9306, -0.3466, -0.4914,  0.3723, -0.4681,\n",
      "          0.7900,  0.1672, -0.6678,  0.2490, -0.1846,  0.1263, -0.5695, -0.3042,\n",
      "         -0.7128, -0.9365, -0.3539,  0.9474, -0.2907, -0.8144,  0.0772, -0.2475,\n",
      "         -0.4978,  0.8651,  0.6012,  0.4015, -0.4040,  0.4070,  0.3090,  0.5832,\n",
      "         -0.7988, -0.0556,  0.3843, -0.3653, -0.7773, -0.9721, -0.4445,  0.5775,\n",
      "          0.9861,  0.7290,  0.2662,  0.4521, -0.1925,  0.5127, -0.9424,  0.9750,\n",
      "         -0.2887,  0.3023, -0.2468,  0.4179, -0.7698,  0.2839,  0.7938, -0.4883,\n",
      "         -0.8031,  0.0017, -0.4663, -0.4759, -0.6109,  0.4805, -0.2281, -0.3361,\n",
      "         -0.0676,  0.9109,  0.9762,  0.7335,  0.0664,  0.6973, -0.8707, -0.5076,\n",
      "          0.1217,  0.3062,  0.2015,  0.9908, -0.5477, -0.0993, -0.9250, -0.9795,\n",
      "         -0.0079, -0.8833, -0.1566, -0.7456,  0.6672,  0.0678,  0.4883,  0.4483,\n",
      "         -0.9748, -0.7749,  0.4192, -0.3789,  0.5451, -0.2242,  0.5822,  0.9040,\n",
      "         -0.5955,  0.6269,  0.9121, -0.6762, -0.7633,  0.8205, -0.3983,  0.8609,\n",
      "         -0.6536,  0.9847,  0.7391,  0.6071, -0.9219, -0.5780, -0.8392, -0.5358,\n",
      "         -0.0547,  0.1601,  0.8055,  0.6485,  0.3772,  0.3194, -0.6284,  0.9928,\n",
      "         -0.7204, -0.9301, -0.1931, -0.3235, -0.9812,  0.7523,  0.3945, -0.0455,\n",
      "         -0.4772, -0.6090, -0.9419,  0.8870,  0.1146,  0.9863, -0.0934, -0.9001,\n",
      "         -0.5253, -0.9105, -0.1603, -0.2277, -0.3457, -0.0691, -0.9406,  0.5328,\n",
      "          0.5019,  0.4443, -0.7323,  0.9970,  1.0000,  0.9531,  0.8736,  0.8274,\n",
      "         -0.9991, -0.3400,  1.0000, -0.9568, -1.0000, -0.9075, -0.5450,  0.3963,\n",
      "         -1.0000, -0.1952, -0.0286, -0.9091,  0.5298,  0.9693,  0.9814, -1.0000,\n",
      "          0.7715,  0.9415, -0.6538,  0.8670, -0.3549,  0.9648,  0.5517,  0.3540,\n",
      "         -0.1722,  0.4046, -0.8642, -0.8626, -0.4459, -0.4753,  0.9896,  0.1439,\n",
      "         -0.7896, -0.9152,  0.1988, -0.1645, -0.1676, -0.9538, -0.2949,  0.3437,\n",
      "          0.7440,  0.0743,  0.3200, -0.7030,  0.2706, -0.0856,  0.3684,  0.6936,\n",
      "         -0.9473, -0.6266, -0.4142, -0.1885, -0.5641, -0.9507,  0.9492, -0.4237,\n",
      "          0.5584,  1.0000,  0.1807, -0.8616,  0.6572,  0.2733, -0.4038,  1.0000,\n",
      "          0.7832, -0.9692, -0.5689,  0.6326, -0.5461, -0.6011,  0.9991, -0.2858,\n",
      "         -0.5600, -0.1067,  0.9659, -0.9861,  0.9850, -0.8755, -0.9561,  0.9429,\n",
      "          0.9229, -0.4665, -0.6514,  0.1411, -0.6770,  0.3809, -0.9308,  0.6122,\n",
      "          0.4780, -0.0258,  0.8438, -0.8002, -0.5618,  0.3295, -0.3962,  0.0836,\n",
      "          0.8161,  0.5594, -0.2335,  0.0892, -0.4048, -0.3592, -0.9596,  0.3258,\n",
      "          1.0000, -0.1662,  0.4800, -0.4787, -0.1197, -0.0520,  0.5287,  0.5652,\n",
      "         -0.3029, -0.8699,  0.5846, -0.9431, -0.9823,  0.7400,  0.2355, -0.3370,\n",
      "          1.0000,  0.4827,  0.2335,  0.2240,  0.9384,  0.0197,  0.5074,  0.8172,\n",
      "          0.9730, -0.3021,  0.5800,  0.7571, -0.7735, -0.3261, -0.6515,  0.0907,\n",
      "         -0.8871,  0.0875, -0.9453,  0.9626,  0.7193,  0.4227,  0.2334,  0.4947,\n",
      "          1.0000, -0.6629,  0.6335, -0.1565,  0.7835, -0.9980, -0.8089, -0.3431,\n",
      "         -0.0795, -0.6944, -0.4076,  0.3220, -0.9566,  0.6802,  0.4113, -0.9812,\n",
      "         -0.9871, -0.0480,  0.7155,  0.0661, -0.9477, -0.6603, -0.5315,  0.3979,\n",
      "         -0.2784, -0.9244, -0.0602, -0.2937,  0.5195, -0.2324,  0.5879,  0.7451,\n",
      "          0.6801, -0.2987, -0.1953, -0.1409, -0.7961,  0.8359, -0.7939, -0.7816,\n",
      "         -0.2600,  1.0000, -0.4334,  0.7989,  0.7585,  0.6576, -0.2056,  0.2703,\n",
      "          0.8742,  0.3035, -0.7009, -0.6686, -0.6283, -0.4853,  0.5271,  0.1574,\n",
      "          0.6235,  0.7427,  0.6226,  0.2126, -0.0307, -0.1011,  0.9984, -0.0992,\n",
      "          0.0031, -0.5022, -0.1029, -0.3473, -0.3635,  1.0000,  0.3314,  0.4783,\n",
      "         -0.9875, -0.7088, -0.9249,  1.0000,  0.8169, -0.6732,  0.4485,  0.5188,\n",
      "         -0.0860,  0.7734, -0.2473, -0.3552,  0.3712,  0.2648,  0.9386, -0.5796,\n",
      "         -0.9632, -0.6271,  0.4750, -0.9509,  0.9995, -0.5100, -0.3215, -0.3629,\n",
      "         -0.0737,  0.3733, -0.0159, -0.9751, -0.1817,  0.2669,  0.9452,  0.2924,\n",
      "         -0.5730, -0.9152,  0.5148,  0.4851, -0.7417, -0.9271,  0.9546, -0.9761,\n",
      "          0.6132,  1.0000,  0.2621, -0.3924,  0.0666, -0.3457,  0.3790, -0.3342,\n",
      "          0.5812, -0.9243, -0.3621, -0.2822,  0.2519, -0.1379,  0.0837,  0.7151,\n",
      "          0.2976, -0.5287, -0.5767,  0.0012,  0.4319,  0.8463, -0.2580, -0.0798,\n",
      "          0.0887, -0.1048, -0.9358, -0.2752, -0.3725, -0.9999,  0.6735, -1.0000,\n",
      "          0.1157,  0.1565, -0.1747,  0.7662,  0.1530,  0.3977, -0.7201, -0.7451,\n",
      "          0.6237,  0.7632, -0.3255, -0.2912, -0.6810,  0.3078, -0.1051,  0.2704,\n",
      "         -0.3966,  0.8059, -0.1633,  1.0000,  0.1728, -0.5765, -0.9547,  0.2762,\n",
      "         -0.2229,  1.0000, -0.8348, -0.9277,  0.5001, -0.6109, -0.8528,  0.3084,\n",
      "         -0.0160, -0.6134, -0.8278,  0.9434,  0.8721, -0.5985,  0.5583, -0.3176,\n",
      "         -0.4700,  0.0788,  0.6485,  0.9755,  0.3102,  0.8003,  0.1091, -0.2434,\n",
      "          0.9564,  0.1951,  0.5436,  0.2562,  1.0000,  0.3236, -0.9076,  0.3451,\n",
      "         -0.9706, -0.2764, -0.9350,  0.2608,  0.2926,  0.8924, -0.2995,  0.9493,\n",
      "         -0.5473,  0.0334, -0.5045, -0.2194,  0.3534, -0.9283, -0.9753, -0.9805,\n",
      "          0.5390, -0.4295, -0.0738,  0.2236,  0.0462,  0.4544,  0.5085, -1.0000,\n",
      "          0.9207,  0.4578,  0.8234,  0.9465,  0.6932,  0.4947,  0.2746, -0.9785,\n",
      "         -0.9677, -0.3696, -0.1632,  0.7423,  0.6396,  0.8590,  0.4738, -0.5504,\n",
      "         -0.2501, -0.4084, -0.5464, -0.9907,  0.5199, -0.3758, -0.9366,  0.9524,\n",
      "         -0.1762, -0.1971, -0.0571, -0.6523,  0.9421,  0.7519,  0.3723,  0.1906,\n",
      "          0.4724,  0.8564,  0.9458,  0.9811, -0.7011,  0.7981, -0.4058,  0.5090,\n",
      "          0.6918, -0.9303,  0.1324,  0.3365, -0.4636,  0.2033, -0.1922, -0.9524,\n",
      "          0.6894, -0.2007,  0.5462, -0.4549,  0.0672, -0.4433, -0.1953, -0.6281,\n",
      "         -0.6344,  0.6549,  0.1976,  0.8689,  0.7786, -0.0730, -0.6112, -0.2296,\n",
      "         -0.6087, -0.8908,  0.9042, -0.0887, -0.3088,  0.3966,  0.0100,  0.8428,\n",
      "          0.1680, -0.3816, -0.3695, -0.6473,  0.8659, -0.1542, -0.6511, -0.6729,\n",
      "          0.6449,  0.3682,  0.9999, -0.6241, -0.8015, -0.2551, -0.3621,  0.4222,\n",
      "         -0.4626, -1.0000,  0.3779, -0.2830,  0.6389, -0.4405,  0.3707, -0.4606,\n",
      "         -0.9731, -0.3115,  0.2298,  0.6131, -0.5001, -0.4934,  0.6239, -0.1378,\n",
      "          0.9326,  0.8194, -0.2299,  0.2172,  0.6442, -0.4101, -0.6729,  0.8688]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "text = \"Bring data science to life with Iguazio!\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model file and register with Iguazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.model.ModelArtifact at 0x7ffdd886fbd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pickle import dumps\n",
    "\n",
    "model_data = dumps(model)\n",
    "\n",
    "project.log_model(key='bert-base-uncased', \n",
    "                  body=model_data, \n",
    "                  model_file='bert-base-uncased.pkl',\n",
    "                  framework=\"PyTorch\",\n",
    "                  algorithm='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model from Iguazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from mlrun.artifacts import get_model\n",
    "\n",
    "model_file, model_obj, _ = get_model('store://models/default/bert-base-uncased')\n",
    "model2 = load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0724,  0.1518, -0.1076,  ..., -0.3008,  0.1606,  0.4223],\n",
      "         [ 0.1667, -0.2562, -0.0170,  ...,  0.1399,  0.6332, -0.0106],\n",
      "         [-0.2398, -0.5034,  0.7445,  ..., -0.5338,  0.1721,  0.4689],\n",
      "         ...,\n",
      "         [ 0.1391, -0.2378,  0.3950,  ..., -0.1814, -0.2512,  0.3334],\n",
      "         [-0.1951, -0.1774, -0.4429,  ...,  0.7163, -0.1154, -0.3983],\n",
      "         [ 0.8002,  0.0795, -0.2366,  ...,  0.2992, -0.7405, -0.2355]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8777, -0.3466, -0.7859,  0.7636,  0.3192, -0.0406,  0.8808,  0.3264,\n",
      "         -0.6340, -1.0000, -0.3372,  0.7651,  0.9787,  0.6349,  0.9301, -0.6971,\n",
      "         -0.1388, -0.6554,  0.3605, -0.5844,  0.7168,  0.9999,  0.1679,  0.3189,\n",
      "          0.5397,  0.9556, -0.7769,  0.9285,  0.9424,  0.6922, -0.7314,  0.2183,\n",
      "         -0.9820, -0.2805, -0.8716, -0.9896,  0.3713, -0.7212,  0.0130,  0.0349,\n",
      "         -0.8949,  0.2738,  0.9999,  0.0101,  0.2831, -0.3270, -1.0000,  0.2574,\n",
      "         -0.8385,  0.7437,  0.6762,  0.4606,  0.1859,  0.5370,  0.4520,  0.0083,\n",
      "         -0.0953,  0.0864, -0.2178, -0.5224, -0.6079,  0.3247, -0.7957, -0.8733,\n",
      "          0.7342,  0.6144, -0.1899, -0.3692, -0.0340, -0.0295,  0.8527,  0.2935,\n",
      "         -0.0815, -0.8645,  0.4616,  0.2433, -0.6444,  1.0000, -0.4868, -0.9622,\n",
      "          0.6861,  0.6583,  0.6026, -0.1201,  0.5905, -1.0000,  0.3676, -0.0947,\n",
      "         -0.9857,  0.2678,  0.4697, -0.2136,  0.4728,  0.6358, -0.5858, -0.5075,\n",
      "         -0.2408, -0.6989, -0.3751, -0.2285,  0.1460, -0.3199, -0.2373, -0.4399,\n",
      "          0.3565, -0.4643, -0.3309,  0.5686,  0.0289,  0.7175,  0.3797, -0.3978,\n",
      "          0.4588, -0.9511,  0.6984, -0.3399, -0.9840, -0.6459, -0.9858,  0.6344,\n",
      "         -0.2784, -0.2379,  0.9410, -0.1459,  0.3988, -0.1058, -0.6132, -1.0000,\n",
      "         -0.6208, -0.5531, -0.1686, -0.3675, -0.9615, -0.9386,  0.5650,  0.9459,\n",
      "          0.2192,  0.9997, -0.3732,  0.9306, -0.3466, -0.4914,  0.3723, -0.4681,\n",
      "          0.7900,  0.1672, -0.6678,  0.2490, -0.1846,  0.1263, -0.5695, -0.3042,\n",
      "         -0.7128, -0.9365, -0.3539,  0.9474, -0.2907, -0.8144,  0.0772, -0.2475,\n",
      "         -0.4978,  0.8651,  0.6012,  0.4015, -0.4040,  0.4070,  0.3090,  0.5832,\n",
      "         -0.7988, -0.0556,  0.3843, -0.3653, -0.7773, -0.9721, -0.4445,  0.5775,\n",
      "          0.9861,  0.7290,  0.2662,  0.4521, -0.1925,  0.5127, -0.9424,  0.9750,\n",
      "         -0.2887,  0.3023, -0.2468,  0.4179, -0.7698,  0.2839,  0.7938, -0.4883,\n",
      "         -0.8031,  0.0017, -0.4663, -0.4759, -0.6109,  0.4805, -0.2281, -0.3361,\n",
      "         -0.0676,  0.9109,  0.9762,  0.7335,  0.0664,  0.6973, -0.8707, -0.5076,\n",
      "          0.1217,  0.3062,  0.2015,  0.9908, -0.5477, -0.0993, -0.9250, -0.9795,\n",
      "         -0.0079, -0.8833, -0.1566, -0.7456,  0.6672,  0.0678,  0.4883,  0.4483,\n",
      "         -0.9748, -0.7749,  0.4192, -0.3789,  0.5451, -0.2242,  0.5822,  0.9040,\n",
      "         -0.5955,  0.6269,  0.9121, -0.6762, -0.7633,  0.8205, -0.3983,  0.8609,\n",
      "         -0.6536,  0.9847,  0.7391,  0.6071, -0.9219, -0.5780, -0.8392, -0.5358,\n",
      "         -0.0547,  0.1601,  0.8055,  0.6485,  0.3772,  0.3194, -0.6284,  0.9928,\n",
      "         -0.7204, -0.9301, -0.1931, -0.3235, -0.9812,  0.7523,  0.3945, -0.0455,\n",
      "         -0.4772, -0.6090, -0.9419,  0.8870,  0.1146,  0.9863, -0.0934, -0.9001,\n",
      "         -0.5253, -0.9105, -0.1603, -0.2277, -0.3457, -0.0691, -0.9406,  0.5328,\n",
      "          0.5019,  0.4443, -0.7323,  0.9970,  1.0000,  0.9531,  0.8736,  0.8274,\n",
      "         -0.9991, -0.3400,  1.0000, -0.9568, -1.0000, -0.9075, -0.5450,  0.3963,\n",
      "         -1.0000, -0.1952, -0.0286, -0.9091,  0.5298,  0.9693,  0.9814, -1.0000,\n",
      "          0.7715,  0.9415, -0.6538,  0.8670, -0.3549,  0.9648,  0.5517,  0.3540,\n",
      "         -0.1722,  0.4046, -0.8642, -0.8626, -0.4459, -0.4753,  0.9896,  0.1439,\n",
      "         -0.7896, -0.9152,  0.1988, -0.1645, -0.1676, -0.9538, -0.2949,  0.3437,\n",
      "          0.7440,  0.0743,  0.3200, -0.7030,  0.2706, -0.0856,  0.3684,  0.6936,\n",
      "         -0.9473, -0.6266, -0.4142, -0.1885, -0.5641, -0.9507,  0.9492, -0.4237,\n",
      "          0.5584,  1.0000,  0.1807, -0.8616,  0.6572,  0.2733, -0.4038,  1.0000,\n",
      "          0.7832, -0.9692, -0.5689,  0.6326, -0.5461, -0.6011,  0.9991, -0.2858,\n",
      "         -0.5600, -0.1067,  0.9659, -0.9861,  0.9850, -0.8755, -0.9561,  0.9429,\n",
      "          0.9229, -0.4665, -0.6514,  0.1411, -0.6770,  0.3809, -0.9308,  0.6122,\n",
      "          0.4780, -0.0258,  0.8438, -0.8002, -0.5618,  0.3295, -0.3962,  0.0836,\n",
      "          0.8161,  0.5594, -0.2335,  0.0892, -0.4048, -0.3592, -0.9596,  0.3258,\n",
      "          1.0000, -0.1662,  0.4800, -0.4787, -0.1197, -0.0520,  0.5287,  0.5652,\n",
      "         -0.3029, -0.8699,  0.5846, -0.9431, -0.9823,  0.7400,  0.2355, -0.3370,\n",
      "          1.0000,  0.4827,  0.2335,  0.2240,  0.9384,  0.0197,  0.5074,  0.8172,\n",
      "          0.9730, -0.3021,  0.5800,  0.7571, -0.7735, -0.3261, -0.6515,  0.0907,\n",
      "         -0.8871,  0.0875, -0.9453,  0.9626,  0.7193,  0.4227,  0.2334,  0.4947,\n",
      "          1.0000, -0.6629,  0.6335, -0.1565,  0.7835, -0.9980, -0.8089, -0.3431,\n",
      "         -0.0795, -0.6944, -0.4076,  0.3220, -0.9566,  0.6802,  0.4113, -0.9812,\n",
      "         -0.9871, -0.0480,  0.7155,  0.0661, -0.9477, -0.6603, -0.5315,  0.3979,\n",
      "         -0.2784, -0.9244, -0.0602, -0.2937,  0.5195, -0.2324,  0.5879,  0.7451,\n",
      "          0.6801, -0.2987, -0.1953, -0.1409, -0.7961,  0.8359, -0.7939, -0.7816,\n",
      "         -0.2600,  1.0000, -0.4334,  0.7989,  0.7585,  0.6576, -0.2056,  0.2703,\n",
      "          0.8742,  0.3035, -0.7009, -0.6686, -0.6283, -0.4853,  0.5271,  0.1574,\n",
      "          0.6235,  0.7427,  0.6226,  0.2126, -0.0307, -0.1011,  0.9984, -0.0992,\n",
      "          0.0031, -0.5022, -0.1029, -0.3473, -0.3635,  1.0000,  0.3314,  0.4783,\n",
      "         -0.9875, -0.7088, -0.9249,  1.0000,  0.8169, -0.6732,  0.4485,  0.5188,\n",
      "         -0.0860,  0.7734, -0.2473, -0.3552,  0.3712,  0.2648,  0.9386, -0.5796,\n",
      "         -0.9632, -0.6271,  0.4750, -0.9509,  0.9995, -0.5100, -0.3215, -0.3629,\n",
      "         -0.0737,  0.3733, -0.0159, -0.9751, -0.1817,  0.2669,  0.9452,  0.2924,\n",
      "         -0.5730, -0.9152,  0.5148,  0.4851, -0.7417, -0.9271,  0.9546, -0.9761,\n",
      "          0.6132,  1.0000,  0.2621, -0.3924,  0.0666, -0.3457,  0.3790, -0.3342,\n",
      "          0.5812, -0.9243, -0.3621, -0.2822,  0.2519, -0.1379,  0.0837,  0.7151,\n",
      "          0.2976, -0.5287, -0.5767,  0.0012,  0.4319,  0.8463, -0.2580, -0.0798,\n",
      "          0.0887, -0.1048, -0.9358, -0.2752, -0.3725, -0.9999,  0.6735, -1.0000,\n",
      "          0.1157,  0.1565, -0.1747,  0.7662,  0.1530,  0.3977, -0.7201, -0.7451,\n",
      "          0.6237,  0.7632, -0.3255, -0.2912, -0.6810,  0.3078, -0.1051,  0.2704,\n",
      "         -0.3966,  0.8059, -0.1633,  1.0000,  0.1728, -0.5765, -0.9547,  0.2762,\n",
      "         -0.2229,  1.0000, -0.8348, -0.9277,  0.5001, -0.6109, -0.8528,  0.3084,\n",
      "         -0.0160, -0.6134, -0.8278,  0.9434,  0.8721, -0.5985,  0.5583, -0.3176,\n",
      "         -0.4700,  0.0788,  0.6485,  0.9755,  0.3102,  0.8003,  0.1091, -0.2434,\n",
      "          0.9564,  0.1951,  0.5436,  0.2562,  1.0000,  0.3236, -0.9076,  0.3451,\n",
      "         -0.9706, -0.2764, -0.9350,  0.2608,  0.2926,  0.8924, -0.2995,  0.9493,\n",
      "         -0.5473,  0.0334, -0.5045, -0.2194,  0.3534, -0.9283, -0.9753, -0.9805,\n",
      "          0.5390, -0.4295, -0.0738,  0.2236,  0.0462,  0.4544,  0.5085, -1.0000,\n",
      "          0.9207,  0.4578,  0.8234,  0.9465,  0.6932,  0.4947,  0.2746, -0.9785,\n",
      "         -0.9677, -0.3696, -0.1632,  0.7423,  0.6396,  0.8590,  0.4738, -0.5504,\n",
      "         -0.2501, -0.4084, -0.5464, -0.9907,  0.5199, -0.3758, -0.9366,  0.9524,\n",
      "         -0.1762, -0.1971, -0.0571, -0.6523,  0.9421,  0.7519,  0.3723,  0.1906,\n",
      "          0.4724,  0.8564,  0.9458,  0.9811, -0.7011,  0.7981, -0.4058,  0.5090,\n",
      "          0.6918, -0.9303,  0.1324,  0.3365, -0.4636,  0.2033, -0.1922, -0.9524,\n",
      "          0.6894, -0.2007,  0.5462, -0.4549,  0.0672, -0.4433, -0.1953, -0.6281,\n",
      "         -0.6344,  0.6549,  0.1976,  0.8689,  0.7786, -0.0730, -0.6112, -0.2296,\n",
      "         -0.6087, -0.8908,  0.9042, -0.0887, -0.3088,  0.3966,  0.0100,  0.8428,\n",
      "          0.1680, -0.3816, -0.3695, -0.6473,  0.8659, -0.1542, -0.6511, -0.6729,\n",
      "          0.6449,  0.3682,  0.9999, -0.6241, -0.8015, -0.2551, -0.3621,  0.4222,\n",
      "         -0.4626, -1.0000,  0.3779, -0.2830,  0.6389, -0.4405,  0.3707, -0.4606,\n",
      "         -0.9731, -0.3115,  0.2298,  0.6131, -0.5001, -0.4934,  0.6239, -0.1378,\n",
      "          0.9326,  0.8194, -0.2299,  0.2172,  0.6442, -0.4101, -0.6729,  0.8688]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model2(**encoded_input)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8df7f603bd25213e082a3cf0c684dc3cf2769221ce262ca9602e257cad1de1f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('igz322')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
